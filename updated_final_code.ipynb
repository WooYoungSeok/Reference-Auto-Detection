{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of NaN values in the 'title' column: 7\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from rapidfuzz import process, fuzz\n",
    "\n",
    "# Sample data loading step\n",
    "data = pd.read_csv('2008_2022_한국현대문학_인문_복합학_추가데이터_참고문헌_박완서.xlsx - Sheet1.csv')\n",
    "\n",
    "nan_count = data['title'].isnull().sum()\n",
    "print(f\"Number of NaN values in the 'title' column: {nan_count}\")\n",
    "\n",
    "# Drop rows where 'title' or 'author' is NaN\n",
    "#data = data.dropna(subset=['title', 'author'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "author\n",
       "박완서    863\n",
       "김윤식    120\n",
       "이선미    110\n",
       "김은하     89\n",
       "김양선     80\n",
       "권명아     72\n",
       "김은정     56\n",
       "최인욱     55\n",
       "김미영     51\n",
       "신수정     51\n",
       "dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.groupby('author').size().sort_values(ascending=False).head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary to hold the best match for each title based on the author\n",
    "title_mapping = {}\n",
    "\n",
    "# Group data by author\n",
    "for author, group in data.groupby('author'):\n",
    "    # Check if the 'author' is NaN and continue to next iteration if so\n",
    "    if pd.isna(author):\n",
    "        continue\n",
    "\n",
    "    titles = group['title'].dropna().unique()  # Drop NaN and get unique titles for this author\n",
    "\n",
    "    for title in titles:\n",
    "        # Generate a list of other titles by the same author to compare against\n",
    "        other_titles = [t for t in titles if t != title]\n",
    "\n",
    "        if other_titles:\n",
    "            # Find the most similar title to the current one (excluding the same title)\n",
    "            best_match, score, _ = process.extractOne(title, other_titles, scorer=fuzz.token_sort_ratio)\n",
    "            \n",
    "            # Apply a threshold to consider as a match\n",
    "            if score > 70:  # threshold of 70 out of 100\n",
    "                title_mapping[(author, title)] = best_match\n",
    "            else:\n",
    "                title_mapping[(author, title)] = title  # no similar title found, map to itself\n",
    "        else:\n",
    "            # If no other titles are available, map the title to itself\n",
    "            title_mapping[(author, title)] = title\n",
    "\n",
    "# Apply the mapping to the 'title' column, handle NaN in 'author' or 'title'\n",
    "data['unified_title'] = data.apply(lambda row: title_mapping.get((row['author'], row['title']), row['title'] if pd.notna(row['title']) else pd.NA), axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 'unified_title' 열에서 각 제목의 빈도 계산\n",
    "title_counts = data['unified_title'].value_counts()\n",
    "\n",
    "# 빈도가 2 이상인 제목만 필터링\n",
    "repeated_titles = title_counts[title_counts > 1].index.tolist()\n",
    "\n",
    "# 'title' 열이 repeated_titles 리스트에 해당하는 경우, 'unified_title' 열을 'title' 열의 값으로 설정\n",
    "data['unified_title'] = data.apply(lambda row: row['title'] if row['title'] in repeated_titles else row['unified_title'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a unique index for each unified title\n",
    "unique_titles = data['unified_title'].unique()\n",
    "title_to_index = {title: idx for idx, title in enumerate(unique_titles)}\n",
    "\n",
    "# Map each 'unified_title' to its unique index\n",
    "data['title_index'] = data['unified_title'].map(title_to_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "unified_title\n",
       "그 많던 싱아는 누가 다 먹었을까                                                  36\n",
       "한국 현대 노년소설 연구                                                       34\n",
       "박완서 문학 길찾기                                                          33\n",
       "그 산이 정말 거기 있었을까                                                     25\n",
       "소설, 노년을 말하다                                                         24\n",
       "                                                                    ..\n",
       "대한민국 아파트 발굴사                                                         1\n",
       "김승옥 각색 시나리오에 내재된 '현대성'과 '여성의 주체구성'연구   -『태양을 훔친 여자』,『강변부인』을 중심으로     1\n",
       "중산층의 몰락과 계급양극화                                                       1\n",
       "과도기 의식과 멜로드라마적 상상력—김승옥의 <강변부인>에 대하여                                  1\n",
       "학병(學兵)의 기억과 국가 - 1940년대 학병의 좌담회와 수기를 중심으로                            1\n",
       "Name: count, Length: 8800, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['unified_title'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the results to a new CSV file\n",
    "data.to_csv('updated_final_ouput.csv', encoding='utf-8-sig', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
